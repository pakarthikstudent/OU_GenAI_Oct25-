{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c195d13-76ed-4662-903b-de84ac3f6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI Types\n",
    "==========\n",
    "Narrow AI - Chatbot,Google Assistant\n",
    "General AI - \n",
    "Super AI -\n",
    "    \n",
    "AI Functionality\n",
    "================\n",
    "Reactive Machines - Responds to input without memory   Ex: Chess-playing \n",
    "Limited Memory  -  Learn from past data to imporve    Ex: self driving cars\n",
    "Theory of Mind - Understand emotions and social interactions\n",
    "\n",
    "\n",
    "1. Collect the data \n",
    "2. Train Model\n",
    "3. Test Model\n",
    "4. Deploy\n",
    "5. Improve \n",
    "==============================================================\n",
    "Data \n",
    "-----\n",
    " |->Text Audio Video Image or any unstructured data ...\n",
    "\n",
    "DataAnalysis\n",
    "==============\n",
    "1. Collect the data -->2. Process Data  -------> 3. EDA  4. Visualization  ===> Model(MachineLearning)\n",
    "                       |->clean up                              \n",
    "                           |->omit duplicate values\n",
    "                           |->replace empty values\n",
    "                           |->drop unwanted columns\n",
    "                           |->drop outliers \n",
    "numpy\n",
    "pandas \n",
    "matplotlib \n",
    "\n",
    "MachineLearning(ML)\n",
    "====================\n",
    "General Program:\n",
    "---------------\n",
    "Programmer:   Input ---->[M/C]-->output\n",
    "Vs\n",
    "ML programming: Input and Output --->[M/C] -->Algorithm(model)\n",
    "\n",
    "1. Collect Data  <== from DataAnalysis \n",
    "2. Prepare\n",
    "3. Select the model \n",
    "4. Train the model\n",
    "5. Test \n",
    "6. Deploy \n",
    "7. Monitor \n",
    "\n",
    "Supervised Learning\n",
    "|->labeled data(input + correct answer)\n",
    "Liner Regression,Decision Tree,...\n",
    "\n",
    "Unsupervised Learning\n",
    "|->no label \n",
    "\n",
    "Reinforcement Learning\n",
    "|->trial and error (ex: sef-driving cars)\n",
    "Graph Machine Learning (GML)\n",
    "-----------------------------\n",
    "  |-> Graph       (pA)--------(pB)\n",
    "       G=(V,E)                 |\n",
    "                      (pC) ----|\n",
    "----------------------------------------------------------\n",
    "\n",
    "Deep Learning Works\n",
    "----------------------\n",
    "1. Collect the data (ex: images,sounds,audios,...)\n",
    "2. Neual Network \n",
    "3. Hidden layers (processing) ...\n",
    "4. Output layers \n",
    "\n",
    "ANN\n",
    "CNN \n",
    "RNN(Recurrent Neual Network) Language Transalation , Speech recognition \n",
    "|\n",
    "Transformer Network  -> NLP,Summarization...\n",
    "====================================================================================\n",
    "GenerativeAI (Gen AI)\n",
    "    |\n",
    "    Create new content(text,image,video,audio..)\n",
    "    LLM ( Text )\n",
    "                       \n",
    "Gen AI LLM - Text - ChatGPT\n",
    "           - Image - DALL-E\n",
    "\n",
    "\n",
    "EndUser: Get list of sales emp's records ? (user input)\n",
    "         -------------------------------\n",
    "                    |                |\n",
    "                    LLM <== pre-trainined ML,DL models \n",
    "                    |  \n",
    "                    VectorDataBase(oracle23 ai,FAISS,Chroma,..)\n",
    "                    ---------------// select *from emp where edept = sales //SQL\n",
    "                                        |\n",
    "Gen AI => Learn from existing data to create new,original content//\n",
    "-------\n",
    "LLM ==> predict the next word in sentence, given all the previous words\n",
    "---\n",
    "===========================================================================\n",
    "Agentic AI - AI Agents\n",
    "                 |->think,plan,take action,use tools \n",
    "\n",
    "Query: travel date -> to delhi  \n",
    "ChatGPT -> .......... travel modes ..\n",
    "                       Vs\n",
    "Query: travel date -> to delhi  \n",
    "      ....    .... visiting places + hotels + ....                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477151e-a797-41f5-a21c-75f9b93b2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP\n",
    "----\n",
    "1. Text preprocessing\n",
    "   - Tokenization\n",
    "   - lemmatization\n",
    "   - stop words\n",
    "2. Text processing\n",
    "   - Bagofwords\n",
    "   - ngram\n",
    "3. Text processing\n",
    "    - word2vector \n",
    "    - Deeplearning techniques \n",
    "       ()  () ()\n",
    "4.  transformer \n",
    "5. BERT \n",
    "-----------------------------\n",
    "2002 -> Supermarket Billing (VB,MSAccess) => Desktop Application\n",
    "         ====================\n",
    "2025 -> ..... pre-trained model + records = own RAG ->chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4166979-4d7d-4c62-87f1-eb7fce68b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Python\n",
    "=======\n",
    " |-> 1. procedure style code = direct approach ->  var = 10 <== direct initialization\n",
    "                                                   def fx():\n",
    "                                                        ..\n",
    "                                                   fx() <== direct call\n",
    "\n",
    " |-> 2. object oriented style code => class<-->object\n",
    "                                                    obj1.var = 10 <== object based initialization\n",
    "                                                    obj2.var = 10 <== object based initialization\n",
    "                                                    obj1.fx() <== methodCall\n",
    "\n",
    " |-> 3. Functional style code => Expression (or) SinglelineCode - computing/analysis.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55ebc6-c150-413c-b2e8-e27938a8ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "In python everything is an object\n",
    "         --------------------------\n",
    "number - int,float,complex\n",
    "a-zA-Z0-9specialchars - str \n",
    "int float complex str bytes bool NoneType \n",
    "list [ ]\n",
    "tuple ( )\n",
    "dict {key:Value,key1:value,Key2:value...}\n",
    "set \n",
    "------------------------------------//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64eb20d-b3ce-4b5e-babb-99f3da623dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='emp.csv'\n",
    "findx=123\n",
    "fsize='5KB'\n",
    "futil = 98.54\n",
    "fstatus = True\n",
    "\n",
    "fileInfo1 = ['emp.csv',123,'5KB',98.54,True] <== list\n",
    "\n",
    "fileInfo2 = ('emp.csv',123,'5KB',98.54,True) <== tuple\n",
    "\n",
    "fileInfo3 = {'K1':'emp.csv','K2':123,'K3':'5KB','K4':98.54,'K5':True} <== dict\n",
    "\n",
    "class classname:\n",
    "    attribute \n",
    "\n",
    "python user defined class - mutable - using classname - we can add new attribute\n",
    "                                                        we can modify an existing attribute\n",
    "                                                        we can delete an existing attribute\n",
    "- template (or) blue print of an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56cdd86-f4d1-4318-bc55-fdd5c7a4e2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.fileInfo'>\n"
     ]
    }
   ],
   "source": [
    "class fileInfo:\n",
    "    fname=''\n",
    "    findex=0\n",
    "print(fileInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d20c2e-e160-40e5-9d4f-69062a66d7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.fileInfo object at 0x000002993696CEC0>\n"
     ]
    }
   ],
   "source": [
    "print(fileInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1aa202-2737-4f92-9f8c-a43224b4b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = fileInfo()\n",
    "obj2 = fileInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed7698a-37da-4bf0-9bec-775de7aae7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.fileInfo'> <class '__main__.fileInfo'>\n"
     ]
    }
   ],
   "source": [
    "print(type(obj1),type(obj2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0469f17-5455-432d-b30e-7f69cbdcdfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(10),type(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b95cbcc-8eaa-4eef-9b0f-355ff9fc7450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.fileInfo at 0x2993677e5d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa9e6e64-e112-40c2-b918-f8841add626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.fileInfo at 0x2993677e710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826149c3-56ae-48ee-9cb1-8d0117d82345",
   "metadata": {},
   "outputs": [],
   "source": [
    " +------------+\n",
    " | [] (white) |   <== blueprint/sheet  -- Class\n",
    " +------------+\n",
    "  |           |_________\n",
    "+------------+         +------------+\n",
    "| [] (white) |         | [] (white) |\n",
    "+------------+         +------------+\n",
    "  1st main                 2nd main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0898f587-90bc-4bac-933f-e4057f2af4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp.csv 101\n"
     ]
    }
   ],
   "source": [
    "class fileInfo:\n",
    "    fname=''\n",
    "    findex=0\n",
    "\n",
    "obj1 = fileInfo()\n",
    "obj1.fname = \"emp.csv\"\n",
    "obj1.findex = 101\n",
    "\n",
    "obj2 = fileInfo()\n",
    "obj2.fname = \"prod.log\"\n",
    "obj2.findex = 102\n",
    "print(obj1.fname,obj1.findex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5702467-1137-4765-bfba-c741211506b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod.log 102\n"
     ]
    }
   ],
   "source": [
    "print(obj2.fname,obj2.findex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb14be3a-1c39-49cc-8629-3828a6fae96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110, 120, 130, 140, 150]\n"
     ]
    }
   ],
   "source": [
    "L=[]\n",
    "\n",
    "def f1(a):\n",
    "    return a+100\n",
    "\n",
    "for var in [10,20,30,40,50]:\n",
    "    r = f1(var)\n",
    "    L.append(r)\n",
    "    \n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddb2781c-434b-412d-b80a-654a1c587e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 120, 130, 140, 150]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda a:a+100,[10,20,30,40,50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c703058e-cf51-4cf2-9a69-d83a795ab758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K1': [110, 120, 130, 140, 150]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "d['K1'] = list(map(lambda a:a+100,[10,20,30,40,50]))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c16fc-60e2-4675-ad20-9b7b37ecf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. lambda\n",
    "---------\n",
    "lambda - python keyword - function call with args and return some value\n",
    "lambda <list of args>:<basicOperation>\n",
    "         .........      ........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bae881c-c805-4841-98e8-f08660254f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(a1,a2):\n",
    "    return a1+a2\n",
    "\n",
    "f1(10,20) # named function call with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7814449-8482-47b6-bb53-979cad24d73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = lambda a1,a2:a1+a2\n",
    "f2(10,20) # unnamed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca78d13-2c11-44d2-9de2-ba362b9305ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110, 120, 130, 140, 150]\n"
     ]
    }
   ],
   "source": [
    "# list comprehesion = list append operation\n",
    "L=[]\n",
    "\n",
    "for var in [10,20,30,40,50]:\n",
    "    r = var+100\n",
    "    L.append(r)\n",
    "    \n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e3813c-d76c-4dd3-84df-8fc189e7618f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 120, 130, 140, 150]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[var+100 for var in [10,20,30,40,50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0ffd50d-fa6e-4b28-979a-58bdf95c31f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'> <class 'function'>\n"
     ]
    }
   ],
   "source": [
    "# Generator - function returns an address(iterator)\n",
    "# ---------   -------- ========= yield ===========\n",
    "\n",
    "def fA():\n",
    "    return 10\n",
    "\n",
    "def fB():\n",
    "    yield 10\n",
    "\n",
    "print(type(fA),type(fB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5da03e0e-11f5-4f67-a91c-5838390de89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fA()))\n",
    "print(type(fB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38571338-0573-47e0-8b1c-56974607cc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object fB at 0x0000029938D1F7F0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cdf80-8924-4c82-a2d5-c3108c077e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. next(genObject) ... StopIteration\n",
    "2. for loop => for var in genObj:\n",
    "                      ..\n",
    "3. type cast to list => list(genObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a48bb9f-c159-45c6-b310-21c90011b041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e81ac-57e5-4eaa-b424-4da2e65d1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "map(function,collection) ->genObject\n",
    "     |          |                |-->typecast to list() ; for loop\n",
    "  lambda    comprehension/inputCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1dae7f5-0db8-4351-b3ee-8083f0585917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 120, 130, 140, 150]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda a:a+100,[10,20,30,40,50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974549e-1e3b-4745-8404-a5ff6f73bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c73c94-7d5e-4bbb-9cf4-d06269291529",
   "metadata": {},
   "outputs": [],
   "source": [
    "python.org\n",
    "------------\n",
    " we can do general python program\n",
    " not ML DL llm DA..\n",
    "pip install numpy\n",
    "pip install pandas\n",
    "...\n",
    "\n",
    "anaconda.com/downloads \n",
    " |->python + ML libs available\n",
    "==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d157c27-a17e-4b38-bc75-a16b2ed2b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "Tokenization is the process of breaking text into smaller pieces (token)\n",
    "token - word / subwords/ characters\n",
    "-----\n",
    " |->Convert to numbers (vector) =>for model understand \n",
    "\n",
    "Hello Good Morning          ..................\n",
    "(English) ------------------>(French..)\n",
    "\n",
    "hello  -> [101030]   \n",
    "good   -> [101010]\n",
    "morning -> [101033]\n",
    "\n",
    "\"I likes to read machine learning algorithm\"\n",
    "word-level => [\"I\", \"likes\", \"to\",\"read\",\"machine\",\"learning\",\"algorithm\"]\n",
    "subword-leve =>[\"I\", \"likes\", \"to\",\"read\",\"machine\", \"learn\",\"ing\",\"algo\",\"rithm\"]\n",
    "\n",
    "NLP terms\n",
    "-----------\n",
    "1. Corpus  - paragraph \n",
    "2. Documents - sentences\n",
    "3. vocabulary - unique words present in the paragraph\n",
    "\n",
    "nltk tool kit <== import nltk\n",
    "download model \n",
    "apply word/sentence///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "329b1f5f-51a3-40bc-a8d1-1ec7f86a598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "048b530a-602c-4144-87a3-952e6ff16a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'likes', 'to', 'read', 'machine', 'learning', 'algorithm']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I likes to read machine learning algorithm\"\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ebdb9-cdb1-4387-a46c-ba19ce637535",
   "metadata": {},
   "outputs": [],
   "source": [
    "LookupError\n",
    ">>> import nltk\n",
    ">>> nltk.download('punkt_tab')\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03140a-8299-4e53-8a7d-b5707266a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed6639-6d94-4718-b056-88f290ace596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hello\" # OK\n",
    "\"hello' # Error \n",
    "'''....\n",
    "   .....'''\n",
    "\"\"\"\n",
    " ....\n",
    " .... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ad1733d-4cc1-428d-9454-86e097b17336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Gen',\n",
       " 'AI',\n",
       " 'NLP',\n",
       " 'lecture',\n",
       " 'pleas',\n",
       " 'do',\n",
       " 'activity',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expect',\n",
       " 'in',\n",
       " 'NLP']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = '''Hello welcome,to Gen AI NLP lecture\n",
    "pleas do activity ! to become expect in NLP'''\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26cb4cd7-a055-4574-bc51-7a84cecacbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello welcome,to Gen AI NLP lecture\\npleas do activity !',\n",
       " 'to become expect in NLP']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5db8827-474f-4d66-b100-a6745a9b145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=\"Hello arun,How are you doing ? OK. I am doing NLP activitites's code ab'c data1.data2 #!/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2908dffa-261a-4bee-ada2-2f49ee8a3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'arun',\n",
       " ',',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'OK',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'doing',\n",
       " 'NLP',\n",
       " 'activitites',\n",
       " \"'s\",\n",
       " 'code',\n",
       " 'ab',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'data1.data2',\n",
       " '#',\n",
       " '!',\n",
       " '/bin']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd35eab4-c960-4beb-a1b9-c833db788ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'arun',\n",
       " ',',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'OK',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'doing',\n",
       " 'NLP',\n",
       " 'activitites',\n",
       " \"'\",\n",
       " 's',\n",
       " 'code',\n",
       " 'ab',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'data1',\n",
       " '.',\n",
       " 'data2',\n",
       " '#!/',\n",
       " 'bin']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7cfcdc6-3fa2-47b7-9417-bf8c91dcf7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.treebank.TreebankWordTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "print(TreebankWordTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc900c24-c5bc-4c3b-88b1-dd094dc56b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\nltk\\\\__init__.py'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca028bc6-aecc-466c-9d90-c46599297ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "<class 'nltk.tokenize.treebank.TreebankWordTokenizer'>\n",
    "nltk/\n",
    "  |__tokenize/\n",
    "            |__treebank.py\n",
    "                    |\n",
    "                    |->class TreebankWordTokenizer:\n",
    "                                 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d43b51c0-577d-4cab-bead-53af2810426d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'do',\n",
       " 'this',\n",
       " ',',\n",
       " 'can',\n",
       " 'i',\n",
       " '?',\n",
       " \"ab'c\",\n",
       " \"def'g\",\n",
       " 'hi',\n",
       " ':',\n",
       " 'j']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg=\"I can't do this, can i? ab'c def'g hi:j\"\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "obj = TreebankWordTokenizer()\n",
    "obj.tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7c45679-64d8-42c1-99bb-40e82ba16cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"They'll test-drive the car tomorrow.\"\n",
    "\n",
    "from nltk.tokenize import word_tokenize,TreebankWordTokenizer,WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65e35bef-f15f-4ae6-803b-b0e9c903d473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', \"'ll\", 'test-drive', 'the', 'car', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56741ef3-a7ea-4ca4-9ed7-6dc43fe1a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', \"'ll\", 'test-drive', 'the', 'car', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "print(TreebankWordTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "127a77e4-f9d8-488b-a11a-ebed2b307fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', \"'\", 'll', 'test', '-', 'drive', 'the', 'car', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "print(WordPunctTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee1be3f3-6719-424b-b1d8-434ac2e69f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## stemming - stem => reduce the root word \n",
    "from nltk.stem import PorterStemmer\n",
    "obj_stemming = PorterStemmer()\n",
    "obj_stemming.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5677c4c2-5e1b-4a0b-9016-3cce09211d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_stemming.stem(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f49f6bee-68ec-45eb-80f4-4a1a176e9474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learn'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_stemming.stem(\"learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12105904-c80e-46c4-80fc-4348f842c1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_stemming.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78668ca3-3577-4745-b593-0d65dafcbd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regex expression\n",
    "from nltk.stem import RegexpStemmer\n",
    "reg_stemm = RegexpStemmer(\"ing$|s$|e$\")\n",
    "reg_stemm.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75e8c085-7fd3-4cb3-975f-fcd5f8ed47c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemm.stem(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4d7bbf4-e01f-425d-8d55-198ecc7f0367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemm.stem(\"abcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21644fe6-6e01-4a50-9e3e-e473c70e6c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemm.stem(\"abcde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3393a402-ce80-4c71-95e5-40c8a3a7a048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization - lemma \n",
    "# reduce root word - based on pos='v' ''\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatize_obj = WordNetLemmatizer()\n",
    "lemmatize_obj.lemmatize(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "334cdb1c-0d30-4fdf-b5c2-95a9cf022c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_obj.lemmatize(\"eating\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c026a5b7-3804-4e85-9ddc-1c440c445e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_obj.lemmatize(\"history\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfe27533-3a85-43b3-b2b5-ac8274a3d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(lemmatize_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735427d7-71df-4ce6-a7bd-304f540b105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "the hotel food is good  => hotel food good => [123,442,552] ->DB ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17778fa6-32de-47c0-a5dd-61963f5a6a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a721ebe1-f47f-494e-8bba-0f1570c4029b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')\n",
    "stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eea75ff3-eac4-4419-b501-32296809e97b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albanian',\n",
       " 'arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'belarusian',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'tamil',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get list stopwords from other language \n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3839f8d6-2ce3-4f2e-ab7b-b5019510be6e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['إذ',\n",
       " 'إذا',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'أف',\n",
       " 'أقل',\n",
       " 'أكثر',\n",
       " 'ألا',\n",
       " 'إلا',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللاتي',\n",
       " 'اللائي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أما',\n",
       " 'إما',\n",
       " 'أن',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'أنا',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'أنى',\n",
       " 'أنى',\n",
       " 'آه',\n",
       " 'آها',\n",
       " 'أو',\n",
       " 'أولاء',\n",
       " 'أولئك',\n",
       " 'أوه',\n",
       " 'آي',\n",
       " 'أي',\n",
       " 'أيها',\n",
       " 'إي',\n",
       " 'أين',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'إيه',\n",
       " 'بخ',\n",
       " 'بس',\n",
       " 'بعد',\n",
       " 'بعض',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بين',\n",
       " 'بيد',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'ثم',\n",
       " 'ثمة',\n",
       " 'حاشا',\n",
       " 'حبذا',\n",
       " 'حتى',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'خلا',\n",
       " 'دون',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ريث',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'شتان',\n",
       " 'عدا',\n",
       " 'عسى',\n",
       " 'عل',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'غير',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فلا',\n",
       " 'فمن',\n",
       " 'في',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'قد',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كم',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'لا',\n",
       " 'لاسيما',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'لئن',\n",
       " 'ليت',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'ما',\n",
       " 'ماذا',\n",
       " 'متى',\n",
       " 'مذ',\n",
       " 'مع',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'منذ',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'ها',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاهنا',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هؤلاء',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهو',\n",
       " 'يا',\n",
       " 'أبٌ',\n",
       " 'أخٌ',\n",
       " 'حمٌ',\n",
       " 'فو',\n",
       " 'أنتِ',\n",
       " 'يناير',\n",
       " 'فبراير',\n",
       " 'مارس',\n",
       " 'أبريل',\n",
       " 'مايو',\n",
       " 'يونيو',\n",
       " 'يوليو',\n",
       " 'أغسطس',\n",
       " 'سبتمبر',\n",
       " 'أكتوبر',\n",
       " 'نوفمبر',\n",
       " 'ديسمبر',\n",
       " 'جانفي',\n",
       " 'فيفري',\n",
       " 'مارس',\n",
       " 'أفريل',\n",
       " 'ماي',\n",
       " 'جوان',\n",
       " 'جويلية',\n",
       " 'أوت',\n",
       " 'كانون',\n",
       " 'شباط',\n",
       " 'آذار',\n",
       " 'نيسان',\n",
       " 'أيار',\n",
       " 'حزيران',\n",
       " 'تموز',\n",
       " 'آب',\n",
       " 'أيلول',\n",
       " 'تشرين',\n",
       " 'دولار',\n",
       " 'دينار',\n",
       " 'ريال',\n",
       " 'درهم',\n",
       " 'ليرة',\n",
       " 'جنيه',\n",
       " 'قرش',\n",
       " 'مليم',\n",
       " 'فلس',\n",
       " 'هللة',\n",
       " 'سنتيم',\n",
       " 'يورو',\n",
       " 'ين',\n",
       " 'يوان',\n",
       " 'شيكل',\n",
       " 'واحد',\n",
       " 'اثنان',\n",
       " 'ثلاثة',\n",
       " 'أربعة',\n",
       " 'خمسة',\n",
       " 'ستة',\n",
       " 'سبعة',\n",
       " 'ثمانية',\n",
       " 'تسعة',\n",
       " 'عشرة',\n",
       " 'أحد',\n",
       " 'اثنا',\n",
       " 'اثني',\n",
       " 'إحدى',\n",
       " 'ثلاث',\n",
       " 'أربع',\n",
       " 'خمس',\n",
       " 'ست',\n",
       " 'سبع',\n",
       " 'ثماني',\n",
       " 'تسع',\n",
       " 'عشر',\n",
       " 'ثمان',\n",
       " 'سبت',\n",
       " 'أحد',\n",
       " 'اثنين',\n",
       " 'ثلاثاء',\n",
       " 'أربعاء',\n",
       " 'خميس',\n",
       " 'جمعة',\n",
       " 'أول',\n",
       " 'ثان',\n",
       " 'ثاني',\n",
       " 'ثالث',\n",
       " 'رابع',\n",
       " 'خامس',\n",
       " 'سادس',\n",
       " 'سابع',\n",
       " 'ثامن',\n",
       " 'تاسع',\n",
       " 'عاشر',\n",
       " 'حادي',\n",
       " 'أ',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ك',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ي',\n",
       " 'ء',\n",
       " 'ى',\n",
       " 'آ',\n",
       " 'ؤ',\n",
       " 'ئ',\n",
       " 'أ',\n",
       " 'ة',\n",
       " 'ألف',\n",
       " 'باء',\n",
       " 'تاء',\n",
       " 'ثاء',\n",
       " 'جيم',\n",
       " 'حاء',\n",
       " 'خاء',\n",
       " 'دال',\n",
       " 'ذال',\n",
       " 'راء',\n",
       " 'زاي',\n",
       " 'سين',\n",
       " 'شين',\n",
       " 'صاد',\n",
       " 'ضاد',\n",
       " 'طاء',\n",
       " 'ظاء',\n",
       " 'عين',\n",
       " 'غين',\n",
       " 'فاء',\n",
       " 'قاف',\n",
       " 'كاف',\n",
       " 'لام',\n",
       " 'ميم',\n",
       " 'نون',\n",
       " 'هاء',\n",
       " 'واو',\n",
       " 'ياء',\n",
       " 'همزة',\n",
       " 'ي',\n",
       " 'نا',\n",
       " 'ك',\n",
       " 'كن',\n",
       " 'ه',\n",
       " 'إياه',\n",
       " 'إياها',\n",
       " 'إياهما',\n",
       " 'إياهم',\n",
       " 'إياهن',\n",
       " 'إياك',\n",
       " 'إياكما',\n",
       " 'إياكم',\n",
       " 'إياك',\n",
       " 'إياكن',\n",
       " 'إياي',\n",
       " 'إيانا',\n",
       " 'أولالك',\n",
       " 'تانِ',\n",
       " 'تانِك',\n",
       " 'تِه',\n",
       " 'تِي',\n",
       " 'تَيْنِ',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'ذانِ',\n",
       " 'ذِه',\n",
       " 'ذِي',\n",
       " 'ذَيْنِ',\n",
       " 'هَؤلاء',\n",
       " 'هَاتانِ',\n",
       " 'هَاتِه',\n",
       " 'هَاتِي',\n",
       " 'هَاتَيْنِ',\n",
       " 'هَذا',\n",
       " 'هَذانِ',\n",
       " 'هَذِه',\n",
       " 'هَذِي',\n",
       " 'هَذَيْنِ',\n",
       " 'الألى',\n",
       " 'الألاء',\n",
       " 'أل',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'ذيت',\n",
       " 'كأيّ',\n",
       " 'كأيّن',\n",
       " 'بضع',\n",
       " 'فلان',\n",
       " 'وا',\n",
       " 'آمينَ',\n",
       " 'آهِ',\n",
       " 'آهٍ',\n",
       " 'آهاً',\n",
       " 'أُفٍّ',\n",
       " 'أُفٍّ',\n",
       " 'أفٍّ',\n",
       " 'أمامك',\n",
       " 'أمامكَ',\n",
       " 'أوّهْ',\n",
       " 'إلَيْكَ',\n",
       " 'إلَيْكَ',\n",
       " 'إليكَ',\n",
       " 'إليكنّ',\n",
       " 'إيهٍ',\n",
       " 'بخٍ',\n",
       " 'بسّ',\n",
       " 'بَسْ',\n",
       " 'بطآن',\n",
       " 'بَلْهَ',\n",
       " 'حاي',\n",
       " 'حَذارِ',\n",
       " 'حيَّ',\n",
       " 'حيَّ',\n",
       " 'دونك',\n",
       " 'رويدك',\n",
       " 'سرعان',\n",
       " 'شتانَ',\n",
       " 'شَتَّانَ',\n",
       " 'صهْ',\n",
       " 'صهٍ',\n",
       " 'طاق',\n",
       " 'طَق',\n",
       " 'عَدَسْ',\n",
       " 'كِخ',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانكم',\n",
       " 'مكانكما',\n",
       " 'مكانكنّ',\n",
       " 'نَخْ',\n",
       " 'هاكَ',\n",
       " 'هَجْ',\n",
       " 'هلم',\n",
       " 'هيّا',\n",
       " 'هَيْهات',\n",
       " 'وا',\n",
       " 'واهاً',\n",
       " 'وراءَك',\n",
       " 'وُشْكَانَ',\n",
       " 'وَيْ',\n",
       " 'يفعلان',\n",
       " 'تفعلان',\n",
       " 'يفعلون',\n",
       " 'تفعلون',\n",
       " 'تفعلين',\n",
       " 'اتخذ',\n",
       " 'ألفى',\n",
       " 'تخذ',\n",
       " 'ترك',\n",
       " 'تعلَّم',\n",
       " 'جعل',\n",
       " 'حجا',\n",
       " 'حبيب',\n",
       " 'خال',\n",
       " 'حسب',\n",
       " 'خال',\n",
       " 'درى',\n",
       " 'رأى',\n",
       " 'زعم',\n",
       " 'صبر',\n",
       " 'ظنَّ',\n",
       " 'عدَّ',\n",
       " 'علم',\n",
       " 'غادر',\n",
       " 'ذهب',\n",
       " 'وجد',\n",
       " 'ورد',\n",
       " 'وهب',\n",
       " 'أسكن',\n",
       " 'أطعم',\n",
       " 'أعطى',\n",
       " 'رزق',\n",
       " 'زود',\n",
       " 'سقى',\n",
       " 'كسا',\n",
       " 'أخبر',\n",
       " 'أرى',\n",
       " 'أعلم',\n",
       " 'أنبأ',\n",
       " 'حدَث',\n",
       " 'خبَّر',\n",
       " 'نبَّا',\n",
       " 'أفعل به',\n",
       " 'ما أفعله',\n",
       " 'بئس',\n",
       " 'ساء',\n",
       " 'طالما',\n",
       " 'قلما',\n",
       " 'لات',\n",
       " 'لكنَّ',\n",
       " 'ءَ',\n",
       " 'أجل',\n",
       " 'إذاً',\n",
       " 'أمّا',\n",
       " 'إمّا',\n",
       " 'إنَّ',\n",
       " 'أنًّ',\n",
       " 'أى',\n",
       " 'إى',\n",
       " 'أيا',\n",
       " 'ب',\n",
       " 'ثمَّ',\n",
       " 'جلل',\n",
       " 'جير',\n",
       " 'رُبَّ',\n",
       " 'س',\n",
       " 'علًّ',\n",
       " 'ف',\n",
       " 'كأنّ',\n",
       " 'كلَّا',\n",
       " 'كى',\n",
       " 'ل',\n",
       " 'لات',\n",
       " 'لعلَّ',\n",
       " 'لكنَّ',\n",
       " 'لكنَّ',\n",
       " 'م',\n",
       " 'نَّ',\n",
       " 'هلّا',\n",
       " 'وا',\n",
       " 'أل',\n",
       " 'إلّا',\n",
       " 'ت',\n",
       " 'ك',\n",
       " 'لمّا',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ا',\n",
       " 'ي',\n",
       " 'تجاه',\n",
       " 'تلقاء',\n",
       " 'جميع',\n",
       " 'حسب',\n",
       " 'سبحان',\n",
       " 'شبه',\n",
       " 'لعمر',\n",
       " 'مثل',\n",
       " 'معاذ',\n",
       " 'أبو',\n",
       " 'أخو',\n",
       " 'حمو',\n",
       " 'فو',\n",
       " 'مئة',\n",
       " 'مئتان',\n",
       " 'ثلاثمئة',\n",
       " 'أربعمئة',\n",
       " 'خمسمئة',\n",
       " 'ستمئة',\n",
       " 'سبعمئة',\n",
       " 'ثمنمئة',\n",
       " 'تسعمئة',\n",
       " 'مائة',\n",
       " 'ثلاثمائة',\n",
       " 'أربعمائة',\n",
       " 'خمسمائة',\n",
       " 'ستمائة',\n",
       " 'سبعمائة',\n",
       " 'ثمانمئة',\n",
       " 'تسعمائة',\n",
       " 'عشرون',\n",
       " 'ثلاثون',\n",
       " 'اربعون',\n",
       " 'خمسون',\n",
       " 'ستون',\n",
       " 'سبعون',\n",
       " 'ثمانون',\n",
       " 'تسعون',\n",
       " 'عشرين',\n",
       " 'ثلاثين',\n",
       " 'اربعين',\n",
       " 'خمسين',\n",
       " 'ستين',\n",
       " 'سبعين',\n",
       " 'ثمانين',\n",
       " 'تسعين',\n",
       " 'بضع',\n",
       " 'نيف',\n",
       " 'أجمع',\n",
       " 'جميع',\n",
       " 'عامة',\n",
       " 'عين',\n",
       " 'نفس',\n",
       " 'لا سيما',\n",
       " 'أصلا',\n",
       " 'أهلا',\n",
       " 'أيضا',\n",
       " 'بؤسا',\n",
       " 'بعدا',\n",
       " 'بغتة',\n",
       " 'تعسا',\n",
       " 'حقا',\n",
       " 'حمدا',\n",
       " 'خلافا',\n",
       " 'خاصة',\n",
       " 'دواليك',\n",
       " 'سحقا',\n",
       " 'سرا',\n",
       " 'سمعا',\n",
       " 'صبرا',\n",
       " 'صدقا',\n",
       " 'صراحة',\n",
       " 'طرا',\n",
       " 'عجبا',\n",
       " 'عيانا',\n",
       " 'غالبا',\n",
       " 'فرادى',\n",
       " 'فضلا',\n",
       " 'قاطبة',\n",
       " 'كثيرا',\n",
       " 'لبيك',\n",
       " 'معاذ',\n",
       " 'أبدا',\n",
       " 'إزاء',\n",
       " 'أصلا',\n",
       " 'الآن',\n",
       " 'أمد',\n",
       " 'أمس',\n",
       " 'آنفا',\n",
       " 'آناء',\n",
       " 'أنّى',\n",
       " 'أول',\n",
       " 'أيّان',\n",
       " 'تارة',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'حقا',\n",
       " 'صباح',\n",
       " 'مساء',\n",
       " 'ضحوة',\n",
       " 'عوض',\n",
       " 'غدا',\n",
       " 'غداة',\n",
       " 'قطّ',\n",
       " 'كلّما',\n",
       " 'لدن',\n",
       " 'لمّا',\n",
       " 'مرّة',\n",
       " 'قبل',\n",
       " 'خلف',\n",
       " 'أمام',\n",
       " 'فوق',\n",
       " 'تحت',\n",
       " 'يمين',\n",
       " 'شمال',\n",
       " 'ارتدّ',\n",
       " 'استحال',\n",
       " 'أصبح',\n",
       " 'أضحى',\n",
       " 'آض',\n",
       " 'أمسى',\n",
       " 'انقلب',\n",
       " 'بات',\n",
       " 'تبدّل',\n",
       " 'تحوّل',\n",
       " 'حار',\n",
       " 'رجع',\n",
       " 'راح',\n",
       " 'صار',\n",
       " 'ظلّ',\n",
       " 'عاد',\n",
       " 'غدا',\n",
       " 'كان',\n",
       " 'ما انفك',\n",
       " 'ما برح',\n",
       " 'مادام',\n",
       " 'مازال',\n",
       " 'مافتئ',\n",
       " 'ابتدأ',\n",
       " 'أخذ',\n",
       " 'اخلولق',\n",
       " 'أقبل',\n",
       " 'انبرى',\n",
       " 'أنشأ',\n",
       " 'أوشك',\n",
       " 'جعل',\n",
       " 'حرى',\n",
       " 'شرع',\n",
       " 'طفق',\n",
       " 'علق',\n",
       " 'قام',\n",
       " 'كرب',\n",
       " 'كاد',\n",
       " 'هبّ']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde094b-60ed-440a-9443-9b22c8724991",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Lunch break."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
