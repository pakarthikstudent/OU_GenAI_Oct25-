{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab795d00-f68d-4b12-8fd7-9ce02c49c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "Langchain\n",
    "|->framework - build applications\n",
    "|->use llm \n",
    "|->it connects LLMs with data\n",
    "============================\n",
    "|->Prompt template\n",
    "|->Chains\n",
    "|->Memory \n",
    "|->Agents \n",
    "|->Document loader \n",
    "|->vector stores\n",
    "==========================\n",
    "|->community documents\n",
    "\n",
    "Chatbot\n",
    "QA\n",
    "Summarization\n",
    "  - emails,reports,articles ..\n",
    "Agent - [10+20 --->memory ------>calculator \n",
    "             ---<--- -  |<----------|\n",
    "RAG\n",
    "-------------------------------------\n",
    "sales.pdf\n",
    "==========\n",
    " 1000's pages  <== chatbot - Q: \n",
    "-------------------------------------\n",
    "    llm-model-ABC <== mathematical formulas/functions/.. \n",
    "\n",
    "sales.log\n",
    "purchase.log\n",
    "..\n",
    "-------------------//data => vectors <== llm <== chat <== Q: last sales count ->120\n",
    "                                         ----                what is sin(30o) -> ...\n",
    "\n",
    "\n",
    "1. Data Loading from various sources\n",
    "                                |->file ... database .... \n",
    "2. split data into multiple chunks\n",
    "3. embedding - vectors\n",
    "4. vector storage (DB)\n",
    "5. similarity search\n",
    "-------------------------\n",
    "6. llm\n",
    "7. prompt <==\n",
    "8. chain\n",
    "9. ....\n",
    "10. User Interface - streamlit ; flask app\n",
    "\n",
    "Ollama model\n",
    "=============\n",
    " |->open source\n",
    " |->research ; learning \n",
    " |->download to local m/c => ollama service - system process/service \n",
    " |->not using API-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e68334-3998-4ea7-9c87-dca2dcbcf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Go to commandline/terminal \n",
    "==============================\n",
    "ollama list\n",
    "|\n",
    "https://ollama.com/\n",
    "|\n",
    "Download ollama package to local system and install it.\n",
    "|\n",
    "C:\\Users\\karth>ollama --version\n",
    "ollama version is 0.12.6\n",
    "\n",
    "C:\\Users\\karth>ollama -v\n",
    "ollama version is 0.12.6\n",
    "\n",
    "C:\\Users\\karth>ollama list  # list of available model \n",
    "NAME    ID    SIZE    MODIFIED\n",
    "\n",
    "ollama pull <modelName> # download only\n",
    "ollama run <modelName> # run the model\n",
    "(or)\n",
    "ollama run <modelName> # down and run  if model is not exists\n",
    "\n",
    "C:\\Users\\karth>ollama pull gemma2:2b\n",
    "pulling manifest\n",
    "pulling 7462734796d6: 100% ▕██████████████▏ 1.6 GB\n",
    "pulling e0a42594d802: 100% ▕██████████████▏  358 B\n",
    "pulling 097a36493f71: 100% ▕██████████████▏ 8.4 KB\n",
    "pulling 2490e7468436: 100% ▕██████████████▏   65 B\n",
    "pulling e18ad7af7efb: 100% ▕██████████████▏  487 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "success\n",
    "\n",
    "C:\\Users\\karth>ollama list\n",
    "NAME                       ID              SIZE      MODIFIED\n",
    "gemma2:2b                  8ccf136fdd52    1.6 GB    14 seconds ago\n",
    "nomic-embed-text:latest    0a109f422b47    274 MB    7 minutes ago\n",
    "\n",
    "C:\\Users\\karth>ollama run gemma2:2b {enter}\n",
    ">>> ...\n",
    ">>> ...\n",
    "Ctrl+D (or) Ctrl+C \n",
    "C:\\Users\\karth>ollama rm gemma2:2b  <== delete this model\n",
    "\n",
    "C:\\Users\\karth>ollama list\n",
    "NAME                       ID              SIZE      MODIFIED\n",
    "nomic-embed-text:latest    0a109f422b47    274 MB    7 minutes ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21d3d0-c88e-4b45-92b5-2aeb1a5d92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt \n",
    "\n",
    "in juypter cell\n",
    "! pip install -r requirements.txt\n",
    "\n",
    "https://github.com/pakarthikstudent/OU_GenAI_Oct25-/blob/main/DAY2/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc84076-e52b-4950-8b3b-432b41d245c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a84a41-ebc8-41f5-95c1-597e03184f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_ollama.llms.OllamaLLM'>\n"
     ]
    }
   ],
   "source": [
    "print(OllamaLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a3bc2-956e-4570-95f4-13a8bd301fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_ollama/\n",
    "           |__ llms.py\n",
    "                  |__ class OllamaLLM:\n",
    "                             ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d8d2e-18cd-47ef-a65e-e30a08c67dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# obj = OllamaLLM(model=<modelName>)\n",
    "# obj.invoke('Query') ->result_str\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a29918-1ad4-49c0-a59f-c7f974abec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 2140\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm_obj = OllamaLLM(model=\"gemma2:2b\")\n",
    "result1 = llm_obj.invoke(\"What is GenAI?\")\n",
    "print(type(result1),len(result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a834d1c-d2e1-45ce-8cb5-64106676e7b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenAI, short for **Generative Artificial Intelligence**, is a type of artificial intelligence that focuses on creating new content. \n",
      "\n",
      "**Think of it as AI that can write, draw, code, and even compose music!**\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "* **Learning from Data:** GenAI models are trained on massive amounts of data, such as text, images, code, or audio. This allows them to learn the patterns, relationships, and structures within this data. \n",
      "* **Generating Outputs:** Once trained, they can generate new content based on what they learned. It could be a poem, an image, a piece of music, a summary of text, or even code for specific programs.\n",
      "\n",
      "**Here's how GenAI is used:**\n",
      "\n",
      "* **Text Generation:**  Writing articles, poems, scripts, emails, and more.\n",
      "* **Image Creation:** Generating realistic images from descriptions (like \"a cat wearing a hat\"). \n",
      "* **Code Writing:** Creating basic code in different programming languages based on instructions.\n",
      "* **Translation:** Translating text between different languages with high accuracy.\n",
      "* **Music Composition:**  Generating melodies, harmonies, and song structures.\n",
      "\n",
      "\n",
      "**Examples of GenAI tools:**\n",
      "\n",
      "* ChatGPT (for text generation)\n",
      "* DALL-E 2 (for image generation)\n",
      "* Stable Diffusion (for image generation)\n",
      "* Bard (for text and code generation)\n",
      "* Jukebox (for music generation)\n",
      "\n",
      "\n",
      "**Benefits of GenAI:**\n",
      "\n",
      "* **Faster Content Creation:**  Saves time and effort by automating tasks.\n",
      "* **Increased Creativity:** Opens up new possibilities for artistic expression and content development. \n",
      "* **Personalized Experiences:** Offers customized solutions for individuals or specific needs.\n",
      "\n",
      "\n",
      "**Potential Challenges and Concerns:**\n",
      "\n",
      "* **Accuracy and Bias:** AI models can sometimes generate inaccurate or biased information. \n",
      "* **Ethical Use:**  It's crucial to ensure responsible use of GenAI tools to avoid unintended consequences. \n",
      "\n",
      "\n",
      "Overall, GenAI represents a significant breakthrough in AI technology that promises exciting possibilities for the future. While it presents some challenges, the advancements in this field are constantly expanding and will likely have a lasting impact on various industries. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1000fc-35e6-4ce2-89a0-a9a70c477d9c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "print(\"Hello, World!\") \n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **`print()`:**  This is a built-in function in Python that displays text on the screen. \n",
      "* **`\"Hello, World!\"`:** This is a string of characters enclosed in double quotes. The `print()` function takes this string as input and displays it to the user.\n",
      "\n",
      "\n",
      "**To run the code:**\n",
      "\n",
      "1. **Save the Code:** Save the above code in a file named `hello_world.py`.\n",
      "2. **Open your Terminal/Command Prompt:** Navigate to the directory where you saved the file using the command prompt (or terminal).\n",
      "3. **Run the File:** Type the following command and press Enter: \n",
      "   ```bash\n",
      "   python hello_world.py \n",
      "   ```\n",
      "\n",
      "**Output:**\n",
      "\n",
      "\n",
      "You will see \"Hello, World!\" printed on your screen in your terminal or command prompt.\n",
      "\n",
      "Let me know if you want to learn more about Python programming!  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = llm_obj.invoke(\"How to write Hello world python example?\")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a45b9c-360f-47ba-8e88-6fe28e445ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "myobj = OllamaLLM(model=\"lamma\")\n",
    "# myobj.invoke(\"what is genAI?\")\n",
    "# ResponseError: model 'lamma' not found (status code: 404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087f680-d205-4f2e-939c-ec322338e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mac os\n",
    "conda create -n py312 python=3.12 -y\n",
    "conda activate py312\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=py312 --display-name \"Python 3.12\"\n",
    "Switch to it in Jupyter\n",
    "==========================\n",
    "Open Jupyter Notebook or JupyterLab \n",
    "Go to the Kernel → Change Kernel menu.\n",
    "Choose \"Python 3.12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4528a-e438-4277-8293-454813fcb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load our dataset - langchain_community.document_loaders\n",
    "                                                |->TextLoader\n",
    "                                                |->PDFLoader\n",
    "                                                |->...\n",
    "1. Using document loader class -> Get the document \n",
    "2. doc -> metadata - info about the data + page_content - actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d737b9-c776-4dcb-b2fd-0c980cd0155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.document_loaders.text.TextLoader'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "print(TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e8cc2-3c36-4782-b905-8e12460bf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_object = TextLoader('input_text_file') <== Regular file - ASCII/Text\n",
    "|\n",
    "loader_object.load() ->documents\n",
    "                         |->metadata + page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95908948-ebec-43cc-a58f-5d18284daef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\karth'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35484120-e426-42c7-9b1c-468f962af876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader('my_docs.txt')\n",
    "docs = loader.load()\n",
    "print(type(docs),len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d7c5a5f-04c1-4adf-b528-36bac67198f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'my_docs.txt'}, page_content=\"LangChain is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDevelopment: Build your applications using LangChain's open-source components and third-party integrations. Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\\nProductionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\\nDeployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4918368-285b-47d6-9ca3-11f2387ced45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 15\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader('attention.pdf')\n",
    "docs = pdf_loader.load()\n",
    "print(type(docs),len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e73dce-4c2b-47c3-aa60-30a346812599",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='1 Introduction\n",
      "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\n",
      "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
      "transduction problems such as language modeling and machine translation [ 35, 2, 5]. Numerous\n",
      "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
      "architectures [38, 24, 15].\n",
      "Recurrent models typically factor computation along the symbol positions of the input and output\n",
      "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
      "states ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\n",
      "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "2 Background\n",
      "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n",
      "[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\n",
      "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
      "the number of operations required to relate signals from two arbitrary input or output positions grows\n",
      "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\n",
      "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
      "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
      "End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\n",
      "aligned recurrence and have been shown to perform well on simple-language question answering and\n",
      "language modeling tasks [34].\n",
      "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
      "entirely on self-attention to compute representations of its input and output without using sequence-\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
      "3 Model Architecture\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\n",
      "Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\n",
      "of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\n",
      "sequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\n",
      "[10], consuming the previously generated symbols as additional input when generating the next.\n",
      "2' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-08-03T00:07:29+00:00', 'author': '', 'keywords': '', 'moddate': '2023-08-03T00:07:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "# print(docs)\n",
    "#print(docs[0])\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad3d5b-75a6-4b03-8c14-0c82815a4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ca7b4-2b63-4aec-b7fe-2a89642d5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests - GET - download webcontent from external URL\n",
    "bs4 - extract data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d14d9-d69c-46cb-8795-11acf6a7ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.get('URL') ->return_code 200 ->OK  != 200 ->Failed\n",
    "requests.get('URL') ->r.headers -> web header information in dict format\n",
    "download the URL content => r.text / r.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac21253-7310-4668-97c7-89fb8d9533f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get('https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "375bc6b4-aff6-4dd1-8b3f-126bd7825078",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Tue, 28 Oct 2025 07:01:55 GMT', 'Expires': '-1', 'Cache-Control': 'private, max-age=0', 'Content-Type': 'text/html; charset=ISO-8859-1', 'Content-Security-Policy-Report-Only': \"object-src 'none';base-uri 'self';script-src 'nonce-rxIMiqsPOMH2KdH0_LEHEA' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http:;report-uri https://csp.withgoogle.com/csp/gws/other-hp\", 'Accept-CH': 'Sec-CH-Prefers-Color-Scheme', 'P3P': 'CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"', 'Content-Encoding': 'gzip', 'Server': 'gws', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'Set-Cookie': 'AEC=AaJma5sgoFTlUN9pGnvtA4fKuhbFpVvpX7sNsBnIAfGfgzym-fW5zuMeIA; expires=Sun, 26-Apr-2026 07:01:55 GMT; path=/; domain=.google.com; Secure; HttpOnly; SameSite=lax, NID=526=OhAe2PbVKAy4PdW21b7a1UbnKGMud-IlRMaMbiISnyN2CPH2OJNhERmuPwiofnqR1mAa4p7ej_RrpGfvSaniRVuOckyHpM1EpPCDH2KQZY1dELq97Mvjl3GYSAUFDEK4bIdhMlmKs0yVxjqWJqMVdwGlrrhb77Dg8pW9TOHFqhnJAr29KwgzidGgUzxNVF4gwlibR4mI6mMl6FX5fA; expires=Wed, 29-Apr-2026 07:01:54 GMT; path=/; domain=.google.com; HttpOnly', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'Transfer-Encoding': 'chunked'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('https://www.google.com')\n",
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f0a0979-d3d4-4dc9-b81b-c45f44e8f6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/html; charset=ISO-8859-1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cef6ee6-fa9b-4b9c-9345-762026e404e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_web = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d3e7886-0bee-4558-bc4a-b3a7bca3714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 19758\n"
     ]
    }
   ],
   "source": [
    "print(type(google_web),len(google_web))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a10682-1b33-4729-b2f9-7189cd3ff19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For testing\n",
    "# print(google_web)\n",
    "with open('test.html','w') as wobj:\n",
    "    wobj.write(google_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229484ba-b342-429b-b6c6-8132367f391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs4 - extract data \n",
    "bs4.BeautifulSoup(webpageContent) ->object\n",
    "object.<htmlTag> =>data\n",
    "<or>\n",
    "object.find(<htmlTag>) =>data_string\n",
    "<or>\n",
    "object.find_all(<htmlTag>) =>data_list\n",
    "\n",
    "<p class=\"classID\" var=234>\n",
    "<a href=\"URL\">\n",
    "   ------------//use dictionary logic   Key=Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5cce93a-f18d-4b91-97bd-ef45bd2ce374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Google</title>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "web_obj = bs4.BeautifulSoup(google_web)\n",
    "web_obj.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0940f4c5-c981-42ce-83f9-7c1324254e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e040ff1-563f-4e8f-a840-b7bc4999c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Google</title>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('title') # same as web_obj.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7404b528-f16d-458d-b4db-3b127a383d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p style=\"font-size:8pt;color:#636363\">© 2025 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('p') # same as web_obj.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aabbe027-620e-4844-857b-923a289d310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p style=\"font-size:8pt;color:#636363\">© 2025 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4df1d206-0293-4f84-9a75-f69b01fbd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'K1':'V1'}\n",
    "d['K1']\n",
    "# d['Kx'] KeyError: 'Kx'\n",
    "# d.get('K1') -> Value ; d.get('Kx') ->None\n",
    "d.get('Kx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f165ce19-8190-4f8f-9656-7a48fd5adaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p style=\"font-size:8pt;color:#636363\">© 2025 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d9026a8-6c40-4ab6-9f72-a0fd141dc841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'font-size:8pt;color:#636363'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('p').get('style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d52cbaa2-3437-47c9-8b3e-8b6fb1806145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/imghp?hl=en&tab=wi'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf903bff-dbec-4ee8-8416-5a4374e26449",
   "metadata": {},
   "outputs": [],
   "source": [
    "Download list of URLs from google.com\n",
    "Download list of rpm file from yum.oracle.com/OL9/.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cba5aedc-65cf-4f0a-8768-1a5c9dae96b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"gb1\" href=\"https://www.google.com/imghp?hl=en&amp;tab=wi\">Images</a>,\n",
       " <a class=\"gb1\" href=\"https://maps.google.co.in/maps?hl=en&amp;tab=wl\">Maps</a>,\n",
       " <a class=\"gb1\" href=\"https://play.google.com/?hl=en&amp;tab=w8\">Play</a>,\n",
       " <a class=\"gb1\" href=\"https://www.youtube.com/?tab=w1\">YouTube</a>,\n",
       " <a class=\"gb1\" href=\"https://news.google.com/?tab=wn\">News</a>,\n",
       " <a class=\"gb1\" href=\"https://mail.google.com/mail/?tab=wm\">Gmail</a>,\n",
       " <a class=\"gb1\" href=\"https://drive.google.com/?tab=wo\">Drive</a>,\n",
       " <a class=\"gb1\" href=\"https://www.google.co.in/intl/en/about/products?tab=wh\" style=\"text-decoration:none\"><u>More</u> »</a>,\n",
       " <a class=\"gb4\" href=\"http://www.google.co.in/history/optout?hl=en\">Web History</a>,\n",
       " <a class=\"gb4\" href=\"/preferences?hl=en\">Settings</a>,\n",
       " <a class=\"gb4\" href=\"https://accounts.google.com/ServiceLogin?hl=en&amp;passive=true&amp;continue=https://www.google.com/&amp;ec=GAZAAQ\" id=\"gb_70\" target=\"_top\">Sign in</a>,\n",
       " <a href=\"/advanced_search?hl=en-IN&amp;authuser=0\">Advanced search</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=hi&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAY\">हिन्दी</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=bn&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAc\">বাংলা</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=te&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAg\">తెలుగు</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=mr&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAk\">मराठी</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=ta&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAo\">தமிழ்</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=gu&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAs\">ગુજરાતી</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=kn&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAw\">ಕನ್ನಡ</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=ml&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCA0\">മലയാളം</a>,\n",
       " <a href=\"https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&amp;hl=pa&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCA4\">ਪੰਜਾਬੀ</a>,\n",
       " <a href=\"/intl/en/ads/\">Advertising</a>,\n",
       " <a href=\"http://www.google.co.in/services/\">Business Solutions</a>,\n",
       " <a href=\"/intl/en/about.html\">About Google</a>,\n",
       " <a href=\"https://www.google.com/setprefdomain?prefdom=IN&amp;prev=https://www.google.co.in/&amp;sig=K_XQ_d5m-Wvv3qQqxh9hFIekPIKOc%3D\">Google.co.in</a>,\n",
       " <a href=\"/intl/en/policies/privacy/\">Privacy</a>,\n",
       " <a href=\"/intl/en/policies/terms/\">Terms</a>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('https://www.google.com')\n",
    "web_page = r.text\n",
    "gpage = bs4.BeautifulSoup(web_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d23472bb-4299-4fbf-93dc-024b6f851f7b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/imghp?hl=en&tab=wi\n",
      "https://maps.google.co.in/maps?hl=en&tab=wl\n",
      "https://play.google.com/?hl=en&tab=w8\n",
      "https://www.youtube.com/?tab=w1\n",
      "https://news.google.com/?tab=wn\n",
      "https://mail.google.com/mail/?tab=wm\n",
      "https://drive.google.com/?tab=wo\n",
      "https://www.google.co.in/intl/en/about/products?tab=wh\n",
      "http://www.google.co.in/history/optout?hl=en\n",
      "/preferences?hl=en\n",
      "https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/&ec=GAZAAQ\n",
      "/advanced_search?hl=en-IN&authuser=0\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=hi&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAY\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=bn&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAc\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=te&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAg\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=mr&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAk\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=ta&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAo\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=gu&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAs\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=kn&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCAw\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=ml&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCA0\n",
      "https://www.google.com/setprefs?sig=0_DyujMz2tWUzD_X4d7jcsSMLCwEI%3D&hl=pa&source=homepage&sa=X&ved=0ahUKEwjAq8vBrMaQAxVnBrkGHXy3NPgQ2ZgBCA4\n",
      "/intl/en/ads/\n",
      "http://www.google.co.in/services/\n",
      "/intl/en/about.html\n",
      "https://www.google.com/setprefdomain?prefdom=IN&prev=https://www.google.co.in/&sig=K_XQ_d5m-Wvv3qQqxh9hFIekPIKOc%3D\n",
      "/intl/en/policies/privacy/\n",
      "/intl/en/policies/terms/\n"
     ]
    }
   ],
   "source": [
    "for var in gpage.find_all('a'):\n",
    "    print(var.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444e6bc-4feb-4320-93e3-9e74b0d1340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
